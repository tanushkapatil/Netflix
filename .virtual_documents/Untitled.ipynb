#importing lib
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv('netflix_data.csv', lineterminator = '\n')


df.head()


df.info()


df['Genre'].head()


df.duplicated().sum()


df.describe()


df['Release_Date'] = pd.to_datetime(df['Release_Date'])
print(df['Release_Date'].dtypes)


df['Release_Date'] = df['Release_Date'].dt.year
df['Release_Date'].dtypes


df.head()


#Dropping the columns
cols = ['Overview', 'Original_Language', 'Poster_Url']
df.drop(cols, axis = 1, inplace = True)
df.columns


df.head()


def categorize_col(df, col, labels):
    # Calculate the edges based on quartiles
    edges = [
        df[col].describe()['min'] - 1e-6,  # Slightly below min to include minimum value
        df[col].describe()['25%'],
        df[col].describe()['50%'],
        df[col].describe()['75%'],
        df[col].describe()['max'] + 1e-6   # Slightly above max to include maximum value
    ]
    df[col] = pd.cut(df[col], edges, labels = labels, duplicates = 'drop')
    return df


# Define labels for quartiles
labels = ['not_popular', 'below_avg', 'average', 'popular']

# Categorize the 'Vote_Average' column
df = categorize_col(df, 'Vote_Average', labels)

# Verify the changes
print(df['Vote_Average'].unique())


df.head()


df['Vote_Average'].value_counts()


df.dropna(inplace = True)
df.isna().sum()


# Split the genre strings into lists
df['Genre'] = df['Genre'].str.split(', ')

# Explode the lists into separate rows
df = df.explode('Genre').reset_index(drop=True)

# Display the first few rows
df.head()


# Convert the 'Genre' column to category dtype for memory efficiency
df['Genre'] = df['Genre'].astype('category')

# Verify the dtype conversion
print("Genre column dtype after conversion:", df['Genre'].dtype)


df.info()


df.nunique()


sns.set_style('whitegrid')


# Q1: What is the most frequent genre in the dataset?
print("\nQ1: Most frequent genre statistics:")
print(df['Genre'].describe())

# Visualize genre distribution
sns.catplot(y='Genre', data=df, kind='count',
            order=df['Genre'].value_counts().index,
            color='#428775')
plt.title('Genre Distribution in Movies Dataset')
plt.show()


# First ensure Vote_Average is numeric
df['Vote_Average'] = pd.to_numeric(df['Vote_Average'], errors='coerce')
genre_votes = df.groupby('Genre', observed=True)['Vote_Average'].mean().sort_values(ascending=False)
print(genre_votes.head())


# Q2: What genres have the highest votes?
print("\nQ2: Analyzing genres with highest votes:")

plt.figure(figsize=(12, 8))

genre_counts = df['Genre'].value_counts().sort_values(ascending=True)  # Sort ascending for proper plotting

sns.barplot(x=genre_counts.values, 
            y=genre_counts.index,
            color='#428775')

plt.title('Genre Frequency Distribution', fontsize=16, pad=20)
plt.xlabel('Number of Movies', fontsize=12)
plt.ylabel('Genre', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

for i, v in enumerate(genre_counts.values):
    plt.text(v + 0.5, i, str(v), color='black', va='center')

plt.tight_layout()
plt.show()


# Q3: What movie got the highest popularity? What's its genre?
print("\nQ3: Movie with highest popularity:")
max_pop = df[df['Popularity'] == df['Popularity'].max()]
print(max_pop[['Title', 'Genre', 'Popularity']].to_string(index=False))


# Q4: What movie got the lowest popularity? What's its genre?
print("\nQ4: Movie with lowest popularity:")
min_pop = df[df['Popularity'] == df['Popularity'].min()]
print(min_pop[['Title', 'Genre', 'Popularity']].to_string(index=False))



df.head()


# Q5: Which year has the most movies?
print("\nQ5: Year with most movies released:")
df['Release_Date'].hist()
plt.title('Release Date Column Distribution')
plt.show()


import os
os.makedirs('plots', exist_ok=True)


# Number of movies released per year
movies_per_year = df.groupby('Release_Date').size()
plt.figure(figsize=(12, 6))
movies_per_year.plot()
plt.title("Movies Released Per Year")
plt.xlabel("Year")
plt.ylabel("Number of Movies")
plt.grid()
plt.savefig('plots/movies_per_year.png')
plt.show()


plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.savefig('plots/heatmap.png')
plt.show()


genre_year = df.groupby(['Release_Date', 'Genre'], observed=True).size().unstack().fillna(0)
top_genres = df['Genre'].value_counts().head(5).index
genre_year[top_genres].plot(figsize=(14, 6))
plt.title("Top Genre Trends Over the Years")
plt.xlabel("Year")
plt.ylabel("Movie Count")
plt.savefig('plots/top_genres_trend.png')
plt.show()





from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import resample



print(f"Original dataset size: {df.shape}")
print(f"Feature data size before dropna: {X.shape}")
print(f"Target data size before dropna: {y.shape}")

data = pd.concat([X, y], axis=1)
print(f"Data size before dropna: {data.shape}")

print(f"Number of NaNs per column:\n{data.isna().sum()}")



# Check column types
print(df.dtypes)

# Let's create a simple binary label based on Popularity (example)
# For instance, label popular if Popularity > median popularity else unpopular

median_popularity = df['Popularity'].median()
df['Label'] = df['Popularity'].apply(lambda x: 'popular' if x > median_popularity else 'unpopular')

# Use numeric columns for features
feature_columns = ['Vote_Average', 'Vote_Count', 'Popularity']
target_column = 'Label'

# Extract features and target
X = df[feature_columns]
y = df[target_column]

# Now check if X and y have rows
print(f"Feature data size: {X.shape}")
print(f"Target data size: {y.shape}")

# Then encode target
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Now split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)



median_popularity = df['Popularity'].median()

# Create a label column based on popularity threshold
df['Label'] = df['Popularity'].apply(lambda x: 'popular' if x > median_popularity else 'unpopular')



feature_columns = ['Vote_Average', 'Vote_Count', 'Popularity']
target_column = 'Label'

X = df[feature_columns]
y = df[target_column]



print(X.isna().sum())  # should be zero or small
print(y.isna().sum())  # should be zero or small



print(X.head())
print(X.dtypes)



print("Unique classes in y before encoding:", y.unique())
print("Class counts:\n", y.value_counts())



# Example: create categories based on Popularity thresholds
def popularity_label(pop):
    if pop > 4000:
        return 'popular'
    elif pop > 2000:
        return 'average'
    else:
        return 'unpopular'

df['Popularity_Label'] = df['Popularity'].apply(popularity_label)

# Now check the class distribution
print(df['Popularity_Label'].value_counts())



df_majority = df[df['Popularity_Label'] == 'unpopular']
df_minority_avg = df[df['Popularity_Label'] == 'average']
df_minority_pop = df[df['Popularity_Label'] == 'popular']

# Downsample majority
df_majority_downsampled = resample(
    df_majority, 
    replace=False,    # sample without replacement
    n_samples=20,     # number to match a bit more balanced dataset
    random_state=42
)

# Combine
df_balanced = pd.concat([df_majority_downsampled, df_minority_avg, df_minority_pop])

print(df_balanced['Popularity_Label'].value_counts())



le_vote_avg = LabelEncoder()
X_train['Vote_Average'] = le_vote_avg.fit_transform(X_train['Vote_Average'])
X_test['Vote_Average'] = le_vote_avg.transform(X_test['Vote_Average'])



X_train = pd.get_dummies(X_train)
X_test = pd.get_dummies(X_test)

# Align columns to ensure train and test have same features
X_test = X_test.reindex(columns=X_train.columns, fill_value=0)



clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)



y_pred = clf.predict(X_test)



print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))



importances = clf.feature_importances_
feat_names = X_train.columns
sorted_idx = importances.argsort()

plt.figure(figsize=(8,6))
plt.barh(feat_names[sorted_idx], importances[sorted_idx], color='purple')
plt.title("Feature Importance from Random Forest")
plt.show()










